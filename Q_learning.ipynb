{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Il3waFud1ABY"
      ],
      "authorship_tag": "ABX9TyMwcyz2P7RttbrPFxzCSbjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZAHID188/Q-learning_collab/blob/main/Q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n"
      ],
      "metadata": {
        "id": "dFFqzO8SskVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7G8KqhHzK9W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DeepQNetwork Class\n",
        "\n",
        "learning rate =lr, number of action=n_actions,name= name of actions ,fcl_dim= fully connected layer dimension"
      ],
      "metadata": {
        "id": "iLkBGEIqsPg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class deeepQNetwork(object):\n",
        "  #learning rate =lr, number of action=n_actions,name= name of actions\n",
        "  #fcl_dim= fully connected layer dimension,\n",
        "  def __init__(self,lr,n_actions,name,fcl_dims=256,input_dims=(210,160,4),chkpt_dir='tmp/dqn'):\n",
        "    self.lr=lr\n",
        "    self.name=name\n",
        "    self.n_actions=n_actions\n",
        "    self.fcl_dims=fcl_dims\n",
        "    self.input_dims=input_dims\n",
        "    self.sess=tf.Session()\n",
        "    self.build_network()\n",
        "    self.sess.run(tf.global_variables_initializer())\n",
        "    self.saver=tf.train.Saver()\n",
        "    self.checkpoint_file=os.path.join(chkpt_dir,'deepqnet.ckpt')\n",
        "    self.params=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=self.name)\n"
      ],
      "metadata": {
        "id": "Jpy1vD4K0DGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of the Code Avobe"
      ],
      "metadata": {
        "id": "5wRRnPJnw0gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, let's break down the code and explain each part:\n",
        "\n",
        "\n",
        "\n",
        "> `class deeepQNetwork(object):`\n",
        "\n",
        "\n",
        "This line defines a new class called deeepQNetwork which inherits from the base object class in Python.\n",
        "\n",
        "\n",
        "> `def __init__(self, lr, n_actions, name, fcl_dims=256, input_dims=(210, 160, 4), chkpt_dir='tmp/dqn'):`\n",
        "\n",
        "\n",
        "\n",
        "This is the constructor method` (__init__)` for the deeepQNetwork class. It initializes the object with the following parameters:\n",
        "\n",
        "\n",
        "\n",
        "1.  `lr:` Learning rate for the neural network.\n",
        "2. ` n_actions:` The number of possible actions in the environment.\n",
        "3. `name:` A string representing the name of the network.\n",
        "4. `fcl_dims=256:` The dimension of the fully connected layer in the neural network. The default value is set to 256.\n",
        "5. `input_dims=(210, 160, 4):` The dimensions of the input data. In this case, it's a tuple of (210, 160, 4), which could represent the shape of an image or some other input data.\n",
        "6. `chkpt_dir='tmp/dqn':` The directory path where the checkpoint files (model weights) will be saved or loaded from. The default value is set to 'tmp/dqn'.\n",
        "> self.lr = lr\n",
        ">\n",
        "> self.name = name\n",
        ">\n",
        ">self.n_actions = n_actions\n",
        ">\n",
        ">self.fcl_dims = fcl_dims\n",
        ">\n",
        ">self.input_dims = input_dims\n",
        ">\n",
        ">self.sess = tf.Session()\n",
        "\n",
        ">These lines store the parameter values as instance variables (self.lr, self.name, self.n_actions, self.fcl_dims, self.input_dims) and create a new TensorFlow session (self.sess)."
      ],
      "metadata": {
        "id": "5C-9_5bvw_5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the net"
      ],
      "metadata": {
        "id": "MiUt0_m8vWmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def build_net(self):\n",
        "    with tf.variable_scope(self.name):\n",
        "      self.input = tf.placeholder(tf.float32,\n",
        "                                        shape=[None, *self.input_dims],\n",
        "                                        name='inputs')\n",
        "      self.actions = tf.placeholder(tf.float32,\n",
        "                                          shape=[None, self.n_actions],\n",
        "                                          name='action_taken')\n",
        "      self.q_target = tf.placeholder(tf.float32,\n",
        "                                           shape=[None, self.n_actions],\n",
        "                                           name='q_value')\n",
        "      conv1 = tf.layers.conv2d(inputs=self.input, filters=32,\n",
        "                                     kernel_size=(8,8), strides=4, name='conv1',\n",
        "                     kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
        "      conv1_activated = tf.nn.relu(conv1)\n",
        "\n",
        "\n",
        "      conv2 = tf.layers.conv2d(inputs=conv1_activated, filters=64,\n",
        "                                     kernel_size=(4,4), strides=2, name='conv2',\n",
        "                      kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
        "      conv2_activated = tf.nn.relu(conv2)\n",
        "\n",
        "\n",
        "      conv3 = tf.layers.conv2d(inputs=conv2_activated, filters=128,\n",
        "                                     kernel_size=(3,3),strides=1, name='conv3',\n",
        "                      kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
        "      conv3_activated = tf.nn.relu(conv3)\n",
        "      flat = tf.layers.flatten(conv3_activated)\n",
        "      dense1 = tf.layers.dense(flat, units=self.fc1_dims,\n",
        "                                     activation=tf.nn.relu,\n",
        "                    kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
        "\n",
        "      self.Q_values = tf.layers.dense(dense1, units=self.n_actions,\n",
        "                    kernel_initializer=tf.variance_scaling_initializer(scale=2))\n",
        "\n",
        "      #self.q = tf.reduce_sum(tf.multiply(self.Q_values, self.actions))\n",
        "\n",
        "      self.loss = tf.reduce_mean(tf.square(self.Q_values - self.q_target))\n",
        "\n",
        "      self.train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n"
      ],
      "metadata": {
        "id": "BDjgvfbvvc8v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXP"
      ],
      "metadata": {
        "id": "Il3waFud1ABY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "self.build_network()\n",
        "This line calls the build_network method, which is likely responsible for constructing the neural network architecture. The implementation of this method is not shown in the provided code snippet.\n",
        "\n",
        "python\n",
        "Copy\n",
        "self.sess.run(tf.global_variables_initializer())\n",
        "This line initializes all the global variables (weights and biases) in the TensorFlow graph.\n",
        "\n",
        "python\n",
        "Copy\n",
        "self.saver = tf.train.Saver()\n",
        "This line creates a Saver object, which is used for saving and restoring the model's weights and variables.\n",
        "\n",
        "python\n",
        "Copy\n",
        "self.checkpoint_file = os.path.join(chkpt_dir, 'deepqnet.ckpt')\n",
        "This line constructs the path for the checkpoint file where the model's weights will be saved or loaded from. It joins the chkpt_dir path with the filename 'deepqnet.ckpt'.\n",
        "\n",
        "python\n",
        "Copy\n",
        "self.params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=self.name)\n",
        "This line retrieves all the trainable variables (weights and biases) from the TensorFlow graph that are associated with the scope self.name. These variables will be used during the training process.\n",
        "\n",
        "In summary, this code defines a class deeepQNetwork that represents a deep Q-network (DQN) used in reinforcement learning. The class initializes the necessary parameters, creates a TensorFlow session, builds the neural network architecture (not shown), initializes variables, creates a saver for checkpointing, and retrieves the trainable variables from the TensorFlow graph. The DQN is likely used to approximate the Q-value function, which represents the expected cumulative reward for taking a particular action in a given state of the environment."
      ],
      "metadata": {
        "id": "__uFkSbX0u9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EmBD9dFP0_v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WAY OF SAVING FILES"
      ],
      "metadata": {
        "id": "5UYEe1iD7Auc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(self):\n",
        "  print(\"...Loading checkpoint...\")\n",
        "  self.saver.restore(self.sess, self.checkpoint_file)\n",
        "\n",
        "def save_checkpoint(self):\n",
        "  print(\"...Saving checkpoint...\")\n",
        "  self.saver.save(self.sess, self.checkpoint_file)"
      ],
      "metadata": {
        "id": "ZgoRzXQ27Fpc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "agent"
      ],
      "metadata": {
        "id": "2voIuX7B7uwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, alpha, gamma, mem_size, n_actions, epsilon, batch_size,\n",
        "                 replace_target=10000, input_dims=(210,160,4),\n",
        "                 q_next_dir='tmp/q_next', q_eval_dir='tmp/q_eval'):\n",
        "        self.action_space = [i for i in range(n_actions)]\n",
        "        self.n_actions = n_actions\n",
        "        self.gamma = gamma\n",
        "        self.mem_size = mem_size\n",
        "        self.mem_cntr = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.batch_size = batch_size\n",
        "        self.replace_target = replace_target\n",
        "        self.q_next = DeepQNetwork(alpha, n_actions, input_dims=input_dims,\n",
        "                                   name='q_next', chkpt_dir=q_next_dir)\n",
        "        self.q_eval = DeepQNetwork(alpha, n_actions, input_dims=input_dims,\n",
        "                                   name='q_eval', chkpt_dir=q_eval_dir)\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_dims))\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *input_dims))\n",
        "        self.action_memory = np.zeros((self.mem_size, self.n_actions),\n",
        "                                      dtype=np.int8)\n",
        "        self.reward_memory = np.zeros(self.mem_size)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.int8)"
      ],
      "metadata": {
        "id": "l_3JHtO27wAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}